- I am a Bachelor student in Artificial Intelligence at [Radboud University](https://www.ru.nl/en/education/bachelors/artificial-intelligence), Nijmegen, Netherlands, with former education in Philosophy, Neuroscience, and Cognition, as well as Psychology. My academic interests are:
	- Steering towards a mechanistic understanding of neural networks.
	- Understanding of the cognitive mechanisms of controllability estimation.
	- The intersection of artificial and natural intelligence, i.e. can the field of AI learn from natural intelligence research and vice versa?
	- Novel brain imaging and modulation devices, such as fTUS. Generally, adaptive BCI applications!
- One of my previous projects revolved around the [Natural Abstractions Hypothesis](https://www.alignmentforum.org/tag/natural-abstraction#:~:text=The%20Natural%20Abstraction%20hypothesis%20says,dimensional%20than%20the%20system%20itself.) by [John Wentworth](https://www.linkedin.com/in/wentworthjohn/). where I worked together with [Jan](https://universalprior.substack.com/) on understanding how the brain populates its cognitive maps with natural concepts. I have also previous written about [[Artificial Sentience]], [[Ethics]] and [[Personal]] topics.
- One of my ongoing project revolves around the fascinating concept of [‘Hebbian’ Natural Abstractions](https://www.snellessen.com/sequence-hebbian-natural-abstractions), which is a variant of the [Natural Abstractions Hypothesis](https://www.alignmentforum.org/posts/Nwgdq6kHke5LY692J/alignment-by-default#Unsupervised__Natural_Abstractions). If you are not familiar with this hypothesis, it suggests that a) the universe abstracts well into concepts, b) that these concepts are high-level summaries of low-level systems and c) that these concepts are “natural”, meaning that we should expect a wide range of cognitive agents to converge onto finding them. If this hypothesis is correct, we could more reliably specify what it is that we want AI systems to do (e.g. specify a high-level description of the physical configuration of a desirable world). Together with [Jan](https://universalprior.substack.com/), with whom I am working on this project, we want to understand how the brain populates its cognitive maps with said concepts. I also enjoy writing on other topics, from ethics, artificial sentience and maybe whole brain emulation, so [reach out](https://t.me/deroeko) if you'd like to collaborate!
- Before diving into this area, I was actively involved in the climate movement, where I contributed as a UX designer and worked with organizations such as [Together for Future e.V.](https://togetherforfuture.org/) and [Future Matters Project](https://en.futuremattersproject.org/). In these roles, I focused on project management, team development, and knowledge management.
- When I'm not immersed in my academic pursuits, I enjoy various hobbies. For example, I like to read, bouldering, playing guitar and piano, and riding my bike (a lovely Koga Miyata Carbon Tech 5000). I also sympathize with *some* views of the [Effective Altruism](https://www.effectivealtruism.org/) and [Rationality community](https://lesswrong.com/) (though I disagree on many parts as well; in general, I try to [keep my identity small](http://www.paulgraham.com/identity.html) and [form my own views](https://forum.effectivealtruism.org/posts/8RcFQPiza2rvicNqw/minimal-trust-investigations)).
- If you’re interested in any of the aforementioned topics, the easiest method to contact me is via [Telegram](https://t.me/deroeko) (~1-3 days answering delay usually – but 100% response rate), otherwise you can use my [email](https://www.notion.so/Home-d61c32385b114627b19145dc3a008c15?pvs=21). [Here](https://fffutu.re/1-on-1s) you can also book a 1-on-1 with me or [give me anonymous feedback](https://fffutu.re/samfeedback) (I love reading feedback!). Also: I subscribe to [Crocker’s Rules](http://sl4.org/crocker.html), so feel free to optimize your message for information, rather than being nice (this does not imply reciprocity).